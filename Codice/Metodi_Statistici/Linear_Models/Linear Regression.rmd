---
title: "R Notebook"
output: html_notebook
---

```{r}
library(readr)

cell_file <- "Codice/Metodi_Statistici/lagged_datasets/Cella_15.csv"
cell_number <- 18
target_y <- readRDS("y.rds")

#leggiamo il dataset della cella
cella <- read_csv(cell_file)
cella$Date <- NULL  # rimuove la prima colonna dato che ha l'orario
spec(cella) # per vedere se ci sono problemi
```

```{r}
library(tidyverse)
# fix colonne
# cella$PompaGlicoleMarcia <- as.factor(cella$PompaGlicoleMarcia)
# cella$Raffreddamento <- as.factor(cella$Raffreddamento)
# cella$VentilatoreMarcia <- as.factor(cella$VentilatoreMarcia)

# separa dataset
targets <- cella %>% select(starts_with(paste0(target_y,"F")))
cella <- cella %>% select(-starts_with(paste0(target_y,"F")))


cella$TemperaturaMandataGlicoleNominale <- NULL
# cella$TemperaturaMandataGlicole
cella$PompaGlicoleMarcia <- NULL


# cella$VentilatoreMarcia <- NULL
```

```{r}
cella <- as_tibble(cella)
summary(cella) # assicuriamoci che vada tutto# bene
```

```{r}
library(Metrics)

# suddivisione
DATASET_SIZE <- nrow(cella)

TEST_SIZE <- 0.2
# TUNING_SIZE <- 0.8

K_FOLDS <- 10


id_test <- as.integer(DATASET_SIZE * (1 - TEST_SIZE)):DATASET_SIZE

cella_test <- cella[id_test,]
cella_train <- cella[-id_test,]



#                   shuffle
partitions <- split(sample(seq_len(nrow(cella))), cut_number(seq_len(nrow(cella)), K_FOLDS, labels = FALSE))



createDFs <- function(df, partitions, partition_number = 1) {
  # partizione indicata
  valid <- df[unlist(partitions[partition_number]),]
  # tutte le partizioni tranne quella indicata
  tr <- df[-unlist(partitions[partition_number]),]
  return(list(training = tr, validation = valid))
}

compute_metrics <- function(name = "dummy", preds = sample(seq(from = 0, to = 4, by = 0.5), replace = TRUE),
                            test = sample(seq(from = 0, to = 4, by = 0.5), replace = TRUE)) {
  error <- data.frame(name = name,
                      mse = mse(actual = test, predicted = preds), # mean square error
                      rmse = rmse(actual = test, predicted = preds), # root mean square error
                      rmsle = rmsle(actual = test, predicted = preds), # root mean square log error
                      rrse = rrse(actual = test, predicted = preds), # root relative square error
                      rse = rse(actual = test, predicted = preds), # relative square error
                      bias = bias(actual = test, predicted = preds), # bias del modello
                      pbias = percent_bias(actual = test, predicted = preds), # percent bias
                      mae = mae(actual = test, predicted = preds), # Mean Absolute Error
                      rae = rae(actual = test, predicted = preds), # relative absolute error
                      mape = mape(actual = test, predicted = preds), # Mean Absolute Percentage Error
                      mdae = mdae(actual = test, predicted = preds), # Median Absolute Different Error
                      msle = msle(actual = test, predicted = preds), # Mean Squared Log Error
                      smape = smape(actual = test, predicted = preds), #symmetric mean absolute percentage error
                      sse = sse(actual = test, predicted = preds), # sum of the squared differences between two numeric vectors
                      r2 = cor(test, preds)^2
  )

  return(error)
}

library(stringr)
create_formula <- function (y="y", useful_factors="."){
  result <- paste(y, "~ ")
  for(factor in useful_factors){
    result <- paste(result, factor, "+")
  }

  result <-  substring(result, first=1, str_length(result) -1)
  return(result)
}

errors <- compute_metrics()

```

# Regressione lineare semplice
```{r}
# facciamo prima il test su 60
library(glmnet)
library(Metrics)

form <- paste0(target_y,"F15 ~ .")

dataset_train <- cbind(cella_train, targets[-id_test,1])
dataset_test <- cbind(cella_test, targets[id_test,1])

model <- glm( formula = form, family = gaussian, data = dataset_train)
predictions <- predict(model, newdata = dataset_test)

y <- paste0(target_y,"F15")

errors <- rbind(errors,
                compute_metrics(name = "Simple Linear Regression",
                                preds = predictions,
                                test = unlist(dataset_test[y], use.names = FALSE)
                )
)
```
```{r}
summary(model)
```
```{r}
plot(model)
```

```{r}
library(ggplot2)

x <- seq_along(predictions)
df <- data.frame(x,y1=predictions,y2=unlist(dataset_test[y], use.names = FALSE))

ggplot(df, aes(x)) +                    # basic graphical object
  geom_line(aes(y=y1), colour="black") +  # first layer
  geom_line(aes(y=y2), colour="green") + # second layer
        labs(title = "Temperatura Ritorno glicole", subtitle = "Predetta vs attuale") + xlab("Tempo") +
ylab("Temperatura")


```


# Modello ridotto
```{r}
REDUCED_TRESHOLD <- 1e-2 # 0.01%
s <- summary(model)
useful_predictors <- names(which(s$coefficients[, "Pr(>|t|)"] < REDUCED_TRESHOLD)[-1]) # -1 per l-intercept


```
```{r}
formula <- create_formula(y = y, useful_factors = useful_predictors)

model <- glm(formula = formula, family = gaussian, data = dataset_train)
predictions <- predict(model, newdata = dataset_test)

errors <- rbind(errors,
                compute_metrics(name = "Simple Linear Regression (Reduced)",
                                preds = predictions,
                                test = unlist(dataset_test[y], use.names = FALSE)
                )
)

```
```{r}
summary(model)
```
```{r}
plot(model)
```

```{r}
library(ggplot2)

x <- seq_along(predictions)
df <- data.frame(x,y1=predictions,y2=unlist(dataset_test[y], use.names = FALSE))

ggplot(df, aes(x)) +                    # basic graphical object
  geom_line(aes(y=y1), colour="black") +  # first layer
  geom_line(aes(y=y2), colour="green") + # second layer
        labs(title = "Temperatura cella", subtitle = "Predetta vs attuale") + xlab("Tempo") +
ylab("Temperatura")
```

```{r}
saveRDS(formula, file = paste0("Codice/Metodi_Statistici/saved_parameters/Linear_Regression/formula_ridotta_lr_cella_",cell_number,".rds"))
```


# Ridge

```{r}
# per i metodi che richiedono x e y
x_train <- dataset_train %>% select(-(y))
x_train <- data.matrix(x_train)
y_train <- dataset_train %>% select((y))
y_train <- unlist(y_train)

x_test <- dataset_test %>% select(-(y))
x_test <- data.matrix(x_test)
y_test <- dataset_test %>% select((y))
y_test <- unlist(y_test)
```

```{r}
# CV

library(glmnet)
model <- glmnet(x_train, y_train, alpha=0)
cv.out <- cv.glmnet(x_train, y_train, alpha=0, nfolds = K_FOLDS)
# select lambda that minimizes training MSE
bestlam <- cv.out$lambda.min
plot(cv.out)

```
```{r}
predictions <- predict(model, s=bestlam, newx=x_test)

predictions <- unlist(as.data.frame(predictions))
errors <- rbind(errors,
                compute_metrics(name = paste0("Ridge Linear_Regression (Lambda = ", bestlam,")"),
                                preds = predictions,
                                test = y_test
                )
)
```

```{r}
saveRDS(bestlam, file = "Codice/Metodi_Statistici/saved_parameters/Linear_Regression/best_lambda_ridge.rds")
```
```{r}
library(ggplot2)

x <- seq_along(predictions)
df <- data.frame(x,y1=predictions,y2=unlist(dataset_test[y], use.names = FALSE))

ggplot(df, aes(x)) +                    # basic graphical object
  geom_line(aes(y=y1), colour="black") +  # first layer
  geom_line(aes(y=y2), colour="green") + # second layer
        labs(title = "Temperatura cella", subtitle = "Predetta vs attuale") + xlab("Tempo") +
ylab("Temperatura")
```


# Lasso
```{r}
# CV

library(glmnet)
model <- glmnet(x_train, y_train, alpha=1)
cv.out <- cv.glmnet(x_train, y_train, alpha=1, nfolds = K_FOLDS)
# select lambda that minimizes training MSE
bestlam <- cv.out$lambda.min
plot(cv.out)
```

```{r}
predictions <- predict(model, s=bestlam, newx=x_test)

predictions <- unlist(as.data.frame(predictions))
errors <- rbind(errors,
                compute_metrics(name = paste0("Lasso Linear_Regression (Lambda = ", bestlam,")"),
                                preds = predictions,
                                test = y_test
                )
)
```

```{r}
# lasso
saveRDS(bestlam, file = paste0("Codice/Metodi_Statistici/saved_parameters/Linear_Regression/best_lambda_lasso_Cella_",cell_number,".rds"))
```


```{r}
library(ggplot2)

x <- seq_along(predictions)
df <- data.frame(x,y1=predictions,y2=unlist(dataset_test[y], use.names = FALSE))

ggplot(df, aes(x)) +                    # basic graphical object
  geom_line(aes(y=y1), colour="black") +  # first layer
  geom_line(aes(y=y2), colour="green") + # second layer
        labs(title = "Temperatura cella", subtitle = "Predetta vs attuale") + xlab("Tempo") +
ylab("Temperatura")
```

```{r}
saveRDS(object = errors[,-1], file = paste0("Codice/Metodi_Statistici/saved_parameters/metriche_errori/Regressioni_lineari_cella_",cell_number,".rds"))
```

```{r}
dataset_train <- cella_train
dataset_test <- cella_test


test_errors <- compute_metrics()


plots <- NULL

test_for_plot <- data.frame(real=0, predicted=0)
id <- sample(1:2000, 1)


for(i in seq_len(ncol(targets))){
  REDUCED_TRESHOLD <- 1e-2 # 0.01%
  useful_predictors <- "."
  n <- ncol(dataset_train) -1
  y <- paste0(target_y,"F",i*15)
  column <- targets %>% select(matches(paste0(y,"$")))
  column_t <- column[-id_test,]
  dataset_t <- cbind(dataset_train, column_t)
  column_t <- column[id_test,]
  dataset_ts <- cbind(dataset_test, column_t)
  formula <- create_formula(y=y, useful_factors = useful_predictors)

  while (length(useful_predictors) != n) {
    model <- glm(formula = formula, family = gaussian, data = dataset_t)
    n <- length(model$coefficients)-1
    s <- summary(model)
    useful_predictors <- names(which(s$coefficients[, "Pr(>|t|)"] < REDUCED_TRESHOLD)[-1]) # -1 per l-intercept

    if(length(useful_predictors) == 0){
      REDUCED_TRESHOLD <- 1e-1 # 0.01%
      next
    }
    formula <- create_formula(y=y, useful_factors = useful_predictors)

    }
  predictions <- predict(model, newdata = dataset_ts)
  test_errors <- rbind(test_errors,
                compute_metrics(name = paste0("Simple Linear Regression (Reduced)(F",i*15,")"),
                                preds = predictions,
                                test = unlist(dataset_ts[y], use.names = FALSE)
                )
    )

  test_y <- unlist(dataset_ts[y], use.names = FALSE)
  test_for_plot <- rbind(test_for_plot, data.frame(real=test_y[id], predicted=predictions[id]))


    ## plot
    x <- seq_along(predictions)
    df <- data.frame(x,y1=predictions,y2=test_y)

    p <- ggplot(df, aes(x)) +                    # basic graphical object
      geom_line(aes(y=y1), colour="black") +  # first layer
      geom_line(aes(y=y2), colour="green") + # second layer
            labs(title = "Temperatura ritorno glicole", subtitle = "Predetta vs attuale") + xlab("Tempo") +
    ylab(y)

    plots <- c(plots, list(p))

}
```
```{r}
for(p in plots){
  plot(p)
}
```

```{r}
# esempio di predizione
x <- seq(15,180,15)
df <- data.frame(x,y1=test_for_plot$real[-1] ,y2=test_for_plot$predicted[-1])

p <- ggplot(df, aes(x)) +                    # basic graphical object
  geom_line(aes(y=y1), colour="black") +  # first layer
  geom_line(aes(y=y2), colour="green") + # second layer
        labs(title = "Temperatura ritorno glicole", subtitle = "Predetta vs attuale") + xlab("Tempo") +
ylab(y) + ylim(0,3.5)

p
```
