---
title: "R Notebook"
output: html_notebook
---

```{r, results = 'hide'}
library(readr)

lagged <- FALSE
cell_number <- 23

F_PRED <- 60

TEST_SIZE <- 0.2
# TUNING_SIZE <- 0.8
CONFIDENCE_TRESHOLD <- 50 / 100

K_FOLDS <- 10
MAX_TREES <- 500

cell_file <- paste0("Codice/Metodi_Statistici/lagged_datasets/Cella_",cell_number,".csv")
target_y <- readRDS("y.rds")

#leggiamo il dataset della cella
cella <- read_csv(cell_file)

cella$Date <- NULL  # rimuove la prima colonna dato che ha l'orario
# cella$UmiditaRelativa

if(length(summary(cella[target_y])) == 1){
  stop("La variabile da predirre ha un solo livello, non Ã¨ possibile fare il training")
}


cella[,target_y] <- ifelse(cella[,target_y] == 0,  "0",
                    ifelse(cella[,target_y] < 10,  "1-10",
                           ifelse(cella[,target_y] < 20,  "11-20",
                           ifelse(cella[,target_y] < 30,  "21-30",
                           ifelse(cella[,target_y] <40,  "31-40",
                           ifelse(cella[,target_y] < 50,  "41-50",
                           ifelse(cella[,target_y] < 60,  "51-60",
                           ifelse(cella[,target_y] < 70,  "61-70",
                           ifelse(cella[,target_y] < 80,  "71-80",
                           ifelse(cella[,target_y] < 90,  "81-90","91-100"))))))))))
cella[,target_y] <- lapply(cella[target_y], factor)
cella <- droplevels(cella)

for(i in seq(from = 15, to = 180, by = 15)){
    t <- paste0(target_y,"F",i)
cella[,t] <- ifelse(cella[,t] == 0,  "0",
                    ifelse(cella[,t] < 10,  "1-10",
                           ifelse(cella[,t] < 20,  "11-20",
                           ifelse(cella[,t] < 30,  "21-30",
                           ifelse(cella[,t] <40,  "31-40",
                           ifelse(cella[,t] < 50,  "41-50",
                           ifelse(cella[,t] < 60,  "51-60",
                           ifelse(cella[,t] < 70,  "61-70",
                           ifelse(cella[,t] < 80,  "71-80",
                           ifelse(cella[,t] < 90,  "81-90","91-100"))))))))))
  cella[t] <- lapply(cella[t], factor)

  }
# da vedere se conviene convertire anche il resto
if(lagged){
  targets <- NULL
  for(i in seq(from = 1, to = 60, by = 1)){
    targets <- c(targets, paste0(target_y,"P",i))
  }
  cella[targets] <- lapply(cella[target_y], factor)
} else {
  cella <- cella %>% select(-matches(".*P..?$"))
}
rm(targets)

# spec(cella) # per vedere se ci sono problemi

```



```{r}
library(tidyverse)
# separa dataset
targets <- cella %>% select(starts_with(paste0(target_y,"F")))
cella <- cella %>% select(-starts_with(paste0(target_y,"F")))
# if(!lagged){
#   cella <- cella %>% select(-starts_with(paste0(target_y,"P")))
# }

# fix colonne
cella$PompaGlicoleMarcia <- factor(cella$PompaGlicoleMarcia)
cella$Raffreddamento <- factor(cella$Raffreddamento)
cella$VentilatoreMarcia <- factor(cella$VentilatoreMarcia)


y <- paste0(target_y,"F", F_PRED)

cella <- cbind(cella, targets[y])


# cella[y] <- lapply(cella[y], factor)
```

Check
```{r}



```





```{r}
cella <- as_tibble(cella)
summary(cella) # assicuriamoci che vada tutto bene
```



```{r}
library(Metrics)

# suddivisione
DATASET_SIZE <- nrow(cella)

id_test <- as.integer(DATASET_SIZE * (1 - TEST_SIZE)):DATASET_SIZE

cella_test <- cella[id_test,]
cella_train <- cella[-id_test,]


compute_metrics<- function(name = "random guess", preds = sample(0:6, 10,TRUE), test = sample(0:6, 10,TRUE)) {
  error <- data.frame(name = name,
                      accuracy = accuracy(actual = test, predicted = preds), # simple accuracy
                      ce = ce(actual = test, predicted = preds), # classification error
                      f1 = f1(actual = test, predicted = preds) # F1 score
                      # precision = precision(actual = test, predicted = preds), # precision
                      # recall = recall(actual = test, predicted = preds) # recall

  )

  return(error)
}

errors <- compute_metrics()
models <- list(model=NULL)

```




# Simple Tree
```{r}
library(tree)


form <- paste0(y," ~ .")
tree_model <- tree(formula = form, data = cella_train)
summary(tree_model)
plot(tree_model)
text(tree_model, pretty = 0)
title(main = "Tree model for Pompa Glicole Marcia", sub = "Unpruned regression tree")
```

```{r}
predictions <- predict(tree_model, cella_test)

predictions <- unlist(ifelse(predictions > CONFIDENCE_TRESHOLD, 0, 1)[,1], use.names = FALSE)
models <- append(models, list(model=tree_model))
errors <- rbind(errors, compute_metrics(name = "Simple Tree", preds = predictions, test = unlist(cella_test[y], use.names = FALSE)))
```


```{r}
print(errors)

```

## Pruning
```{r}

cv_train <- cv.tree(tree_model, , prune.tree)
# 10 fold cv
plot(cv_train$size, cv_train$dev, type = "b", main = 'Cross-validation: first batch result',
     xlab = 'Tree size', ylab = 'Cross validation error')

# print optimal size
best_size <- cv_train$size[which.min(cv_train$dev)]
paste('Optimal size:', best_size)
saveRDS(best_size, file = paste0("Codice/Metodi_Statistici/saved_parameters/Trees/Pruned_Tree_best_size_cella_",cell_number,".rds"))
```
```{r}
pruned_model <- prune.tree(tree_model, best = best_size)
plot(pruned_model)
text(pruned_model, pretty = 0)
summary(pruned_model)
```

```{r}
predictions <- predict(pruned_model, cella_test)
predictions <- unlist(ifelse(predictions > CONFIDENCE_TRESHOLD, 0, 1)[,1], use.names = FALSE)
models <- append(models, list(model=pruned_model))
errors <- rbind(errors, compute_metrics(
  name = paste0("Pruned Tree (best size: ", best_size),
  preds = predictions,
  test = unlist(cella_test[y], use.names = FALSE)))
```

```{r}
errors
```

## Bagging

```{r}
# NB: Takes a lot
library(randomForest)
max_predictors <- ncol(cella_train) - 1
bagging_model <- randomForest(formula = formula(form), data = cella_train, ntree = MAX_TREES, mtry = max_predictors)
plot(bagging_model)
```

```{r}
predictions <- predict(bagging_model, cella_test)
models <- append(models, list(model=bagging_model))
errors <- rbind(errors, compute_metrics(
  name = paste0("Bagged Tree (N_trees: ", MAX_TREES),
  preds = predictions,
  test = unlist(cella_test[y], use.names = FALSE)))
```

```{r}
errors
```

## Random forest

```{r}
# Ci mette troppo. Ci conviene usare il default
# oob <- NULL
#
# for (m in seq_len(max_predictors - 1)) {
#   rf_tmp <- randomForest(TemperaturaCelle ~ ., data = cella, mtry = m, ntree = MAX_TREES)
#   oob <- c(oob, mean(rf_tmp$oob.times))
# }
#
# minim <- which.min(oob)
# saveRDS(minim, file = paste0("Codice/Metodi_Statistici/saved_parameters/Trees/rf_best_size_cella_", cell_number))
```
```{r}
library(randomForest) # sqrt predittori
rf_model <- randomForest(formula = formula(form), data = cella_train, ntree = MAX_TREES)
plot(rf_model)
varImpPlot(rf_model)
```

```{r}
predictions <- predict(rf_model, cella_test)
models <- append(models, list(model=rf_model))
errors <- rbind(errors, compute_metrics(
  name = paste0("Random Forest (N_trees: ", MAX_TREES),
  preds = predictions,
  test = unlist(cella_test[y], use.names = FALSE)))
```

```{r}
library(plotly)
plot_ly(x=cella$UmiditaRelativa, y=cella$TemperaturaCelle, z=cella$TemperaturaMandataGlicoleNominale, type="scatter3d", mode="markers", color=cella$PercentualeAperturaValvolaMiscelatriceF60)
```


```{r}
errors
```

## Boosting
```{r}
library(caret)

# reference: https://rpubs.com/mpfoley73/529130

# re_encode variables
boosting_model <- train(formula(form),
                        data = cella_train,
                        method = "gbm",  # for bagged tree
                        tuneLength = 5,  # choose up to 5 combinations of tuning parameters
                        trControl = trainControl(
                          method = "cv",  # k-fold cross validation
                          number = K_FOLDS,  # 10 folds
                          savePredictions = "final"      # save predictions for the optimal tuning parameter1
                        )
)
# caret tunes:
#    n.trees: number of boosting iterations
#    interaction.depth: maximum tree depth
#    shrinkage: shrinkage
#   n.minobsinnode: mimimum terminal node size

```
```{r}
plot(boosting_model)
```

```{r}
predictions <- predict(boosting_model, cella_test)
models <- append(models, list(model=boosting_model))
errors <- rbind(errors, compute_metrics(
  name = paste0("Boosted Trees"),
  preds = predictions,
  test = unlist(cella_test[y], use.names = FALSE)))
```

```{r}
errors
```


```{r}
saveRDS(errors, file = paste0("Codice/Metodi_Statistici/saved_parameters/metriche_errori/Alberi_cella_",cell_number,".rds"))
```

```{r}
chosen_model <- which.max(errors$accuracy)
model <- models[chosen_model]$model
if(length(model)==0){
  stop("Random guess is the best model, trees are not adequate")
}

print(paste0("Chosen model: ",errors$name[chosen_model]))
```

```{r}

predictions <- predict(model, cella)
if(length(ncol(predictions)) != 0){
  predictions <- unlist(ifelse(predictions > CONFIDENCE_TRESHOLD, 0, 1)[,1], use.names = FALSE)
} else {
  predictions <- unlist(predictions, use.names = FALSE)
}


final_test_error <- compute_metrics(
  name = errors$name[chosen_model],
  preds = predictions,
  test = unlist(cella[y], use.names = FALSE))
```
```{r}
saveRDS(model, file = paste0("Codice/Metodi_Statistici/saved_models/Cella_",cell_number,"_",errors$name[chosen_model],".rds"))
final_test_error
```
