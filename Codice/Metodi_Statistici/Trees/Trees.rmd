---
title: "R Notebook"
output: html_notebook
---

```{r}
library(readr)

lagged <- FALSE
cell_number <- 18


cell_file <- paste0("Codice/Metodi_Statistici/lagged_datasets/Cella_",cell_number,".csv")
target_y <- readRDS("y.rds")

#leggiamo il dataset della cella
cella <- read_csv(cell_file)
cella$Date <- NULL  # rimuove la prima colonna dato che ha l'orario

spec(cella) # per vedere se ci sono problemi
```

```{r}
# separa dataset
targets <- cella %>% select(starts_with(paste0(target_y,"F")))
cella <- cella %>% select(-starts_with(paste0(target_y,"F")))
if(!lagged){
  cella <- cella %>% select(-starts_with(paste0(target_y,"P")))
}

# fix colonne
cella$PompaGlicoleMarcia <- as.factor(cella$PompaGlicoleMarcia)
cella$Raffreddamento <- as.factor(cella$Raffreddamento)
cella$VentilatoreMarcia <- as.factor(cella$VentilatoreMarcia)

# cella$TemperaturaMandataGlicoleNominale <- NULL
# cella$TemperaturaMandataGlicole
# cella$PompaGlicoleMarcia <- NULL
```

Type any R code in the chunk, for example:
```{r}
library(tidyverse)

cella <- as_tibble(cella)
summary(cella) # assicuriamoci che vada tutto# bene
```

```{r}
library(Metrics)

# suddivisione
DATASET_SIZE <- nrow(cella)

TEST_SIZE <- 0.2
# TUNING_SIZE <- 0.8

K_FOLDS <- 10
MAX_TREES <- 100


id_test <- as.integer(DATASET_SIZE * (1 - TEST_SIZE)):DATASET_SIZE

cella_test <- cella[id_test,]
cella_train <- cella[-id_test,]

# per i metodi che richiedono x e y
x_train <- cella %>% select(-TemperaturaCelle)
x_train <- data.matrix(x_train)
y_train <- cella %>% select(TemperaturaCelle)
y_train <- unlist(y_train)

x_test <- cella_test %>% select(-TemperaturaCelle)
x_test <- data.matrix(x_test)
y_test <- cella_test %>% select(TemperaturaCelle)
y_test <- unlist(y_test)

#                   shuffle
partitions <- split(sample(seq_len(nrow(cella))), cut_number(seq_len(nrow(cella)), K_FOLDS, labels = FALSE))



createDFs <- function(df, partitions, partition_number = 1) {
  # partizione indicata
  valid <- df[unlist(partitions[partition_number]),]
  # tutte le partizioni tranne quella indicata
  tr <- df[-unlist(partitions[partition_number]),]
  return(list(training = tr, validation = valid))
}

compute_metrics_regression <- function(name = "dummy", preds = c(2, 1, 3, 8, 8, 2, 3, 6), test = c(7, 3, 4, 5, 6, 8, 5, 6)) {
  error <- data.frame(name = name,
                      mse = mse(actual = test, predicted = preds), # mean square error
                      rmse = rmse(actual = test, predicted = preds), # root mean square error
                      rmsle = rmsle(actual = test, predicted = preds), # root mean square log error
                      rrse = rrse(actual = test, predicted = preds), # root relative square error
                      rse = rse(actual = test, predicted = preds), # relative square error
                      bias = bias(actual = test, predicted = preds), # bias del modello
                      pbias = percent_bias(actual = test, predicted = preds), # percent bias
                      mae = mae(actual = test, predicted = preds), # Mean Absolute Error
                      rae = rae(actual = test, predicted = preds), # relative absolute error
                      mape = mape(actual = test, predicted = preds), # Mean Absolute Percentage Error
                      mdae = mdae(actual = test, predicted = preds), # Median Absolute Different Error
                      msle = msle(actual = test, predicted = preds), # Mean Squared Log Error
                      smape = smape(actual = test, predicted = preds), #symmetric mean absolute percentage error
                      sse = sse(actual = test, predicted = preds), # sum of the squared differences between two numeric vectors
                      r2 = cor(test, preds)^2
  )

  return(error)
}

errors <- compute_metrics(preds = sample(0:100, size=100, replace = T), test = sample(0:100, size=100, replace = T))
create_plot_predictions <- function (predictions, test_y, true_color, predicted_color, y_name="Percentuale Apertura Valvola Miscelatrice", ylim_inf=0, ylim_sup=100){
  x <- seq_along(predictions)
  df <- data.frame(x,Predetta=predictions,Veri=test_y)


  colors <- c("Predetta" = predicted_color, "Veri" = true_color)


  gg <- ggplot(df, aes(x)) +                    # basic graphical object
  geom_line(aes(y=Predetta, colour="Predetta")) +  # first layer
  geom_line(aes(y=Veri, colour="Veri")) + # second layer
        labs(title = y_name, subtitle = "Predetta vs Valori veri",color = "Legend") +
    scale_color_manual(values = colors) + xlab("Tempo") +
ylab("Temperatura") + ylim(ylim_inf, ylim_sup)
  return(gg)
}

```

# Simple Tree
```{r}
library(tree)
y <- paste0(target_y,"F60")

train_dataset <- cbind(cella_train, targets[-id_test,4])
test_dataset <- cbind(cella_test, targets[id_test,4])
form <- paste0(y," ~ .")
model <- tree(formula = form, data = train_dataset)
summary(model)
plot(model)
text(model, pretty = 0)
title(main = "Tree model for cell Temperature", sub = "Unpruned regression tree")
```

```{r}
predictions <- predict(model, test_dataset)
errors <- rbind(compute_metrics(name = "Simple Tree", preds = predictions, test = unlist(test_dataset[y], use.names = FALSE)))
```


```{r}
library(ggplot2)

create_plot_predictions(predictions, unlist(test_dataset[y]), true_color = "black", predicted_color = "orange" )


```

## Pruning
```{r}

cv_train <- cv.tree(model, , prune.tree)
# 10 fold cv
plot(cv_train$size, cv_train$dev, type = "b", main = 'Cross-validation: first batch result',
     xlab = 'Tree size', ylab = 'Cross validation error')

# print optimal size
best_size <- cv_train$size[which.min(cv_train$dev)]
paste('Optimal size:', best_size)
saveRDS(best_size, file = paste0("Codice/Metodi_Statistici/saved_parameters/Trees/Pruned_Tree_best_size_cella_",cell_number))
```
```{r}
model_pruned <- prune.tree(model, best = best_size)
plot(model_pruned)
text(model_pruned, pretty = 0)
summary(model_pruned)
```

```{r}
predictions <- predict(model_pruned, cella_test)
errors <- rbind(errors, compute_metrics(
  name = paste0("Pruned Tree (best size: ", best_size),
  preds = predictions,
  test = unlist(test_dataset[y], use.names = FALSE)))
```

```{r}
create_plot_predictions(predictions, unlist(test_dataset[y]), true_color = "black", predicted_color = "orange" )
```

## Bagging

```{r}
# NB: Takes a lot
library(randomForest)
max_predictors <- ncol(cella_train) - 1
model_bagging <- randomForest(formula = formula(form), data = train_dataset, ntree = MAX_TREES, mtry = max_predictors)
plot(model_bagging)
```

```{r}
predictions <- predict(model_bagging, test_dataset)
errors <- rbind(errors, compute_metrics(
  name = paste0("Bagged Tree (N_trees: ", MAX_TREES),
  preds = predictions,
  test = unlist(test_dataset[y], use.names = FALSE)))
```

```{r}
create_plot_predictions(predictions, unlist(test_dataset[y]), true_color = "black", predicted_color = "orange" )
```

## Random forest

```{r}
# # Ci mette troppo. Ci conviene usare il default
# mse <- NULL
#
# for (m in seq_len(max_predictors - 1)) {
#   rf_tmp <- randomForest(TemperaturaCelle ~ ., data = cella, mtry = m, ntree = MAX_TREES)
#   mse <- c(mse, mean(rf_tmp$mse))
# }
#
# minim <- which.min(mse)
# saveRDS(minim, file = paste0("Codice/Metodi_Statistici/saved_parameters/Trees/rf_best_size_cella_", cell_number))
```
```{r}
library(randomForest) # p/3 predittori
model_rf <- randomForest(formula = formula(form), data = train_dataset, ntree = MAX_TREES)
plot(model_rf)
varImpPlot(model_rf)
```

```{r}
predictions <- predict(model_rf, test_dataset)
errors <- rbind(errors, compute_metrics(
  name = paste0("Random Forest (N_trees: ", MAX_TREES),
  preds = predictions,
  test = unlist(test_dataset[y], use.names = FALSE)))
```

```{r}
create_plot_predictions(predictions, unlist(test_dataset[y]), true_color = "black", predicted_color = "orange" )
```

## Boosting
```{r}
library(caret)

# reference: https://rpubs.com/mpfoley73/529130

# re_encode variables
boosting_model <- train(formula(form),
                        data = train_dataset,
                        method = "gbm",  # for bagged tree
                        tuneLength = 5,  # choose up to 5 combinations of tuning parameters
                        metric = "mse",  # evaluate hyperparamter combinations with ROC
                        trControl = trainControl(
                          method = "cv",  # k-fold cross validation
                          number = K_FOLDS,  # 10 folds
                          savePredictions = "final"      # save predictions for the optimal tuning parameter1
                        )
)
# caret tunes:
#    n.trees: number of boosting iterations
#    interaction.depth: maximum tree depth
#    shrinkage: shrinkage
#   n.minobsinnode: mimimum terminal node size

```
```{r}
plot(boosting_model)
```

```{r}
predictions <- predict(boosting_model, cella_test)
errors <- rbind(errors, compute_metrics(
  name = paste0("Boosted Trees"),
  preds = predictions,
  test = unlist(test_dataset[y])))
```

```{r}
create_plot_predictions(predictions, unlist(test_dataset[y]), true_color = "black", predicted_color = "orange" )
```


# BART (Bayesian Additive Regression Trees)

NB: bart wants the test in the call, so this is just a display


```{r}
library(BART)
wbart_model <- mc.wbart(x_train, y_train, mc.cores = 8, x.test = x_test)
```
```{r}
errors <- rbind(errors, compute_metrics(
  name = paste0("BART"),
  preds = wbart_model$yhat.test.mean,
  test = unlist(test_dataset[y])))
```
```{r}
create_plot_predictions(wbart_model$yhat.test.mean, unlist(test_dataset[y]), true_color = "black", predicted_color = "orange" )
```

```{r}
saveRDS(errors, file = paste0("Codice/Metodi_Statistici/saved_parameters/metriche_errori/Alberi_cella_",cell_number,".rds"))
```
